# Codveda Technologies Data Science Internship

This repository contains all tasks completed as part of my **Data Science Internship** at **Codveda Technologies**.

---

## Beginner Tasks

### ✅ Task 1: Web Scraping with Python
- Scraped book data from [Books to Scrape](http://books.toscrape.com) using `requests` and `BeautifulSoup`.  
- Extracted **title**, **rating**, **price**, and **availability**.  
- Handled pagination and saved results in CSV using `pandas`.

### ✅ Task 2: Data Cleaning and Preprocessing
- Worked with the [Titanic](https://www.kaggle.com/c/titanic/data) dataset.  
- Handled missing data using **mean**, **median**, **mode**, and **row removal**.  
- Removed outliers using the **IQR method**.  
- Encoded categorical variables with **one-hot encoding**.  
- Normalized numerical columns for model readiness.

### ✅ Task 3: Exploratory Data Analysis (EDA)
- Computed summary statistics (**mean**, **median**, **variance**).  
- Created visualizations including **histograms**, **boxplots**, and **scatter plots**.  
- Generated a **correlation matrix** heatmap to identify feature relationships.

---

## Intermediate Tasks

### ✅ Task 1: Predictive Modeling (Regression)
- Built a **Linear Regression** model using `scikit-learn`.  
- Evaluated using **MSE** and **R²** metrics.  
- Experimented with **Decision Tree Regressor** and **Random Forest Regressor** for performance comparison.

### ✅ Task 2: Classification with Logistic Regression
- Built a **Logistic Regression** classifier to predict categorical outcomes.  
- Evaluated with **Accuracy**, **Precision**, **Recall**, and **ROC curve**.  
- Compared with **Random Forest Classifier** and **Support Vector Machine**.

### ✅ Task 3: Clustering (K-Means)
- Applied **K-Means Clustering** to unlabeled data.  
- Determined optimal cluster count using the **Elbow Method**.  
- Reduced dimensions with **PCA** for 2D visualization.

---

## Advanced Tasks

### ✅ Task 1: Time Series Analysis
- Used stock price data to analyze trends and seasonality.  
- Applied **moving average** and **exponential smoothing**.  
- Built an **ARIMA** forecasting model and evaluated with **RMSE**.

### ✅ Task 2: Natural Language Processing (NLP) - Text Classification
- Preprocessed text (tokenization, stopword removal, lemmatization).  
- Converted text to numerical features using **TF-IDF**.  
- Trained a **Naive Bayes classifier** for sentiment classification.  
- Evaluated with **Precision**, **Recall**, and **F1-score**.

### ✅ Task 3: Neural Networks with TensorFlow/Keras
- Built and trained a **feed-forward neural network** on the **MNIST digit dataset**.  
- Achieved **98% test accuracy**.  
- Plotted **accuracy** and **loss** curves.  
- Tuned hyperparameters (learning rate, batch size) to improve performance.

---

## Tech Stack
- **Languages:** Python  
- **Libraries & Tools:** Pandas, NumPy, Matplotlib, Seaborn, Scikit-learn, Statsmodels, TensorFlow/Keras, NLTK, BeautifulSoup, Requests  

---

You can also visit my [portfolio](https://tahas-portfolio-react.netlify.app/) and [data science portfolio](https://www.datascienceportfol.io/tahalokhandwala) 
